{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318d53d0-ca1a-4b2b-84d1-1ede0d5272b7",
   "metadata": {
    "id": "-5VozRBF37PE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "rcParams[\"figure.figsize\"] = 12, 6\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ab5205-a3ec-41e1-b3cf-218cbb2f1813",
   "metadata": {
    "id": "KJWbFB-tooMg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data(base, seq_size):\n",
    "    df = pd.read_csv(\n",
    "        \"/Users/hn/OneDrive/Doctorado/Tesis/Proyecto Tesis/Codigos/Yahoo/Dataset/A1Benchmark/\"\n",
    "        + base\n",
    "    )\n",
    "    values = df.iloc[:, 1:2]\n",
    "    target = df[\"is_anomaly\"]\n",
    "    test = int(len(df) * 0.5)\n",
    "    x_train = values[:test]\n",
    "    x_test = values[test : len(df)]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data_p = scaler.fit_transform(x_train)\n",
    "    scaled_test = scaler.fit_transform(x_test)\n",
    "\n",
    "    x_train_p = []\n",
    "    for i in range(len(scaled_data_p) - seq_size):\n",
    "        x_train_p.append(scaled_data_p[i : (i + seq_size)])\n",
    "    x_train_p = np.array(x_train_p)\n",
    "\n",
    "    x_test_p = []\n",
    "    for i in range(round(len(scaled_test) / seq_size)):\n",
    "        x_test_p.append(scaled_test[i * seq_size : ((1 + i) * seq_size)])\n",
    "    x_test_p = np.array(x_test_p)\n",
    "\n",
    "    return x_train_p, x_test_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f66fdfb-49e2-4ebe-9aa1-b299a790bf32",
   "metadata": {
    "id": "8jojhgaNxBdw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(neurons, dropout, rec_drop, learning_rate=0.01):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        tf.keras.layers.LSTM(\n",
    "            neurons * 4,\n",
    "            input_shape=(x_train_p.shape[1], x_train_p.shape[2]),\n",
    "            return_sequences=True,\n",
    "        )\n",
    "    )\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(\n",
    "        tf.keras.layers.LSTM(\n",
    "            neurons * 2, recurrent_dropout=rec_drop, return_sequences=True\n",
    "        )\n",
    "    )\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.LSTM(\n",
    "            neurons, recurrent_dropout=rec_drop, return_sequences=False\n",
    "        )\n",
    "    )\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.RepeatVector(x_train_p.shape[1]))\n",
    "    model.add(\n",
    "        tf.keras.layers.LSTM(neurons, recurrent_dropout=rec_drop, return_sequences=True)\n",
    "    )\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.LSTM(\n",
    "            neurons * 2, recurrent_dropout=rec_drop, return_sequences=True\n",
    "        )\n",
    "    )\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(neurons * 4, return_sequences=True))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(TimeDistributed(Dense(x_train_p.shape[2])))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.losses.MeanSquaredError(),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c59589-62cd-48b6-a427-eb751127978b",
   "metadata": {
    "id": "oreO8r7WFdi0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x_train_p, x_test_p) = data(\"real_65.csv\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88321b9-492e-467f-9f81-724dfae90272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=150)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0.0001, patience=5\n",
    ")\n",
    "\n",
    "batch_size = [80, 100]\n",
    "dropout = [0.15, 0.2]\n",
    "rec_drop = [0.15, 0.2]\n",
    "neurons = [16, 32]\n",
    "learning_rate = [0.01, 0.001]\n",
    "param_grid = dict(\n",
    "    neurons=neurons,\n",
    "    dropout=dropout,\n",
    "    rec_drop=rec_drop,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, n_jobs=-1, cv=4, return_train_score=True\n",
    ")\n",
    "\n",
    "\n",
    "grid_result = grid.fit(x_train_p, x_train_p, validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7af8ee5-4e74-40b0-ab59-40a94a4de723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.003187329799402505"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18be0969-3953-4f3e-915d-ac770d2827bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 80,\n",
       " 'dropout': 0.2,\n",
       " 'learning_rate': 0.01,\n",
       " 'neurons': 32,\n",
       " 'rec_drop': 0.15}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d572f394-dbc4-47f9-8cf1-bef639f0047f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resul = pd.DataFrame(grid_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811c8df9-6e1a-47cf-8344-7b30e9da6826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resul.to_excel(\n",
    "    \"/Users/hn/OneDrive/Doctorado/Tesis/Proyecto Tesis/Codigos/Yahoo/Dataset/aut_opt_65.xlsx\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
